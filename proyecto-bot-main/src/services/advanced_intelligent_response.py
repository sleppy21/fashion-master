#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Sistema de Respuesta Inteligente Avanzado con An√°lisis Vectorial
Utiliza embeddings avanzados y an√°lisis sem√°ntico profundo para comprensi√≥n contextual
"""

import pandas as pd
import numpy as np
import json
import re
import pickle
from pathlib import Path
from typing import List, Dict, Tuple, Any, Optional
from dataclasses import dataclass
import logging

# Importaciones para embeddings avanzados
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    print("‚ö†Ô∏è sentence-transformers no disponible, usando TF-IDF como fallback")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.preprocessing import normalize
from sklearn.decomposition import TruncatedSVD
from sklearn.cluster import KMeans

# Configuraci√≥n de rutas
BASE_DIR = Path(__file__).resolve().parent.parent.parent
DATA_DIR = BASE_DIR / "data"
MODELS_DIR = BASE_DIR / "models"

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class QueryAnalysis:
    """Resultado del an√°lisis de una consulta"""
    original_query: str
    processed_query: str
    intent_category: str
    confidence_score: float
    extracted_entities: Dict[str, Any]
    semantic_context: Dict[str, float]
    suggested_responses: List[str]

@dataclass
class ProductMatch:
    """Resultado de b√∫squeda de producto"""
    product: Dict[str, Any]
    similarity_score: float
    match_reasons: List[str]
    confidence_level: str

class AdvancedIntelligentResponseSystem:
    """Sistema de respuesta inteligente avanzado con an√°lisis vectorial profundo"""
    
    def __init__(self, model_name: str = "paraphrase-multilingual-MiniLM-L12-v2"):
        """
        Inicializa el sistema con modelo de embeddings especificado
        
        Args:
            model_name: Nombre del modelo de sentence-transformers a usar
        """
        self.model_name = model_name
        self.sentence_model = None
        self.fallback_vectorizer = TfidfVectorizer(
            stop_words=None, 
            lowercase=True,
            ngram_range=(1, 3),  # Incluir trigramas
            max_features=10000,
            sublinear_tf=True
        )
        
        # Datos
        self.productos_df = None
        self.productos_data = None
        self.faq_data = None
        self.training_data = None
        
        # Vectores y modelos
        self.product_vectors = None
        self.faq_vectors = None
        self.intent_vectors = None
        self.query_examples_vectors = None
        
        # Mapeos y clasificadores
        self.intent_classifier = None
        self.semantic_clusters = None
        self.entity_extractors = self._initialize_entity_extractors()
        
        # Cache de vectores para optimizaci√≥n
        self.vector_cache = {}
        
        # M√©tricas de rendimiento
        self.performance_metrics = {
            'total_queries': 0,
            'successful_matches': 0,
            'high_confidence_responses': 0,
            'fallback_responses': 0
        }
        
    def _initialize_entity_extractors(self) -> Dict[str, Any]:
        """Inicializa extractores de entidades espec√≠ficas"""
        return {
            'talla_patterns': [
                r'\btalla\s*([xsmlXSML]+|\d+)\b',
                r'\b([xsmlXSML]{1,3})\b',
                r'\bn√∫mero\s*(\d+)\b',
                r'\b(extra\s*grande|extra\s*large|muy\s*grande)\b',
                r'\b(extra\s*peque√±a|extra\s*small|muy\s*peque√±a)\b',
                r'\bsize\s*([xsmlXSML]+|\d+)\b'
            ],
            'color_patterns': [
                r'\b(negro|negra|black|oscuro|carbon)\b',
                r'\b(blanco|blanca|white|claro|marfil|hueso|crema)\b',
                r'\b(azul|blue|celeste|marino|√≠ndigo|navy)\b',
                r'\b(rojo|roja|red|bermejo|escarlata|granate|burgundy)\b',
                r'\b(verde|green|esmeralda|oliva|lime|sage)\b',
                r'\b(amarillo|amarilla|yellow|dorado|gold|mostaza)\b',
                r'\b(rosa|pink|rosado|fucsia|magenta)\b',
                r'\b(gris|gray|grey|plomo|plateado|acero|silver)\b',
                r'\b(marr√≥n|brown|caf√©|camel|beige|tierra)\b',
                r'\b(morado|purple|violeta|lila|lavanda)\b',
                r'\b(naranja|orange|coral|durazno|peach)\b'
            ],
            'precio_indicators': [
                r'\b(precio|costo|valor|vale|cuesta|tarifa)\b',
                r'\b(cu√°nto|quanto|how\s*much|cost)\b',
                r'\b(barato|econ√≥mico|cheap|affordable)\b',
                r'\b(caro|costoso|expensive|premium)\b',
                r'\b(oferta|descuento|rebaja|sale|promoci√≥n)\b'
            ],
            'disponibilidad_indicators': [
                r'\b(stock|existencia|disponible|hay|tienen)\b',
                r'\b(agotado|sold\s*out|terminado|acabado)\b',
                r'\b(cu√°ntos|cantidad|quedan|sobran)\b',
                r'\b(llega|viene|restock|reposici√≥n)\b'
            ]
        }
    
    def initialize_embeddings_model(self) -> bool:
        """Inicializa el modelo de embeddings"""
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            logger.warning("sentence-transformers no disponible, usando fallback")
            return False
            
        try:
            logger.info(f"Cargando modelo de embeddings: {self.model_name}")
            self.sentence_model = SentenceTransformer(self.model_name)
            logger.info("‚úÖ Modelo de embeddings cargado exitosamente")
            return True
        except Exception as e:
            logger.error(f"‚ùå Error cargando modelo de embeddings: {e}")
            return False
    
    def load_data(self) -> bool:
        """Carga todos los datos necesarios"""
        try:
            # Cargar productos expandidos
            if (DATA_DIR / "productos_expandidos.json").exists():
                with open(DATA_DIR / "productos_expandidos.json", 'r', encoding='utf-8') as f:
                    self.productos_data = json.load(f)
                self.productos_df = pd.DataFrame(self.productos_data)
                logger.info(f"‚úÖ Cargados {len(self.productos_data)} productos expandidos")
            else:
                # Fallback al cat√°logo original
                with open(DATA_DIR / "catalogue.json", 'r', encoding='utf-8') as f:
                    catalogue = json.load(f)
                    self.productos_data = catalogue.get('productos', [])
                    self.faq_data = catalogue.get('faq', [])
                self.productos_df = pd.DataFrame(self.productos_data)
                logger.info(f"‚úÖ Cargados {len(self.productos_data)} productos del cat√°logo base")
            
            # Cargar FAQ expandidos
            if (DATA_DIR / "context" / "faqs.json").exists():
                with open(DATA_DIR / "context" / "faqs.json", 'r', encoding='utf-8') as f:
                    faq_expanded = json.load(f)
                    self.faq_data = self._flatten_faq_data(faq_expanded)
                logger.info(f"‚úÖ Cargados {len(self.faq_data)} FAQs expandidos")
            
            # Cargar datos de entrenamiento expandidos
            if (DATA_DIR / "preguntas_entrenamiento_expandido.csv").exists():
                self.training_data = pd.read_csv(DATA_DIR / "preguntas_entrenamiento_expandido.csv")
                logger.info(f"‚úÖ Cargados {len(self.training_data)} ejemplos de entrenamiento")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando datos: {e}")
            return False
    
    def _flatten_faq_data(self, faq_expanded: Dict) -> List[Dict]:
        """Aplana la estructura JSON de FAQs para procesamiento"""
        flattened = []
        
        for categoria in faq_expanded.get('preguntas_frecuentes', []):
            cat_name = categoria.get('categoria', 'General')
            for pregunta_data in categoria.get('preguntas', []):
                flattened.append({
                    'categoria': cat_name,
                    'pregunta': pregunta_data.get('pregunta', ''),
                    'respuesta': pregunta_data.get('respuesta', ''),
                    'palabras_clave': pregunta_data.get('palabras_clave', [])
                })
        
        return flattened
    
    def create_advanced_vectors(self) -> bool:
        """Crea vectores avanzados para todos los datos"""
        try:
            logger.info("üîÑ Creando vectores avanzados...")
            
            # Vectores de productos
            if self.productos_data:
                self._create_product_vectors()
            
            # Vectores de FAQ
            if self.faq_data:
                self._create_faq_vectors()
            
            # Vectores de ejemplos de entrenamiento
            if self.training_data is not None:
                self._create_training_vectors()
            
            logger.info("‚úÖ Vectores avanzados creados exitosamente")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error creando vectores: {e}")
            return False
    
    def _create_product_vectors(self):
        """Crea vectores para productos usando embeddings avanzados"""
        product_texts = []
        
        for producto in self.productos_data:
            # Crear texto enriquecido para cada producto
            text_parts = [
                producto.get('nombre', ''),
                producto.get('descripcion', ''),
                producto.get('categoria', ''),
                producto.get('marca', ''),
                producto.get('material', ''),
                ' '.join(producto.get('colores', [])),
                ' '.join(map(str, producto.get('tallas', []))),
                ' '.join(producto.get('etiquetas', []))
            ]
            
            # Agregar informaci√≥n contextual
            if producto.get('destacado'):
                text_parts.append('producto destacado bestseller popular')
            if producto.get('nuevo'):
                text_parts.append('producto nuevo reciente lanzamiento')
            if producto.get('descuento', 0) > 0:
                text_parts.append('oferta descuento promoci√≥n rebaja')
            
            # Agregar contexto de temporada
            temporada = producto.get('temporada', '')
            if temporada:
                text_parts.append(f'temporada {temporada.lower()}')
            
            product_text = ' '.join(text_parts).lower()
            product_texts.append(product_text)
        
        # Crear vectores usando el mejor m√©todo disponible
        if self.sentence_model:
            self.product_vectors = self.sentence_model.encode(product_texts)
            logger.info("‚úÖ Vectores de productos creados con sentence-transformers")
        else:
            self.product_vectors = self.fallback_vectorizer.fit_transform(product_texts)
            logger.info("‚úÖ Vectores de productos creados con TF-IDF")
    
    def _create_faq_vectors(self):
        """Crea vectores para FAQs"""
        if not self.faq_data:
            return
            
        faq_texts = []
        for faq in self.faq_data:
            # Combinar pregunta, respuesta y palabras clave
            text_parts = [
                faq.get('pregunta', ''),
                faq.get('respuesta', ''),
                ' '.join(faq.get('palabras_clave', []))
            ]
            faq_text = ' '.join(text_parts).lower()
            faq_texts.append(faq_text)
        
        if self.sentence_model:
            self.faq_vectors = self.sentence_model.encode(faq_texts)
        else:
            # Usar el mismo vectorizer que productos para consistencia
            try:
                self.faq_vectors = self.fallback_vectorizer.transform(faq_texts)
            except:
                # Si falla, crear nuevo vectorizer
                faq_vectorizer = TfidfVectorizer(stop_words=None, lowercase=True)
                self.faq_vectors = faq_vectorizer.fit_transform(faq_texts)
        
        logger.info("‚úÖ Vectores de FAQ creados")
    
    def _create_training_vectors(self):
        """Crea vectores para datos de entrenamiento"""
        if self.training_data is None or len(self.training_data) == 0:
            return
        
        # Crear vectores para ejemplos de entrenamiento
        training_texts = []
        for _, row in self.training_data.iterrows():
            text_parts = [
                row.get('pregunta', ''),
                row.get('contexto', ''),
                row.get('sinonimos', '')
            ]
            training_text = ' '.join(str(part) for part in text_parts if pd.notna(part)).lower()
            training_texts.append(training_text)
        
        if self.sentence_model:
            self.query_examples_vectors = self.sentence_model.encode(training_texts)
        else:
            try:
                self.query_examples_vectors = self.fallback_vectorizer.transform(training_texts)
            except:
                vectorizer = TfidfVectorizer(stop_words=None, lowercase=True)
                self.query_examples_vectors = vectorizer.fit_transform(training_texts)
        
        logger.info("‚úÖ Vectores de entrenamiento creados")
    
    def analyze_query_semantically(self, query: str) -> QueryAnalysis:
        """Analiza una consulta usando an√°lisis sem√°ntico avanzado"""
        try:
            self.performance_metrics['total_queries'] += 1
            
            # Procesar la consulta
            processed_query = self._preprocess_query(query)
            
            # Extraer entidades
            entities = self._extract_entities(query)
            
            # Clasificar intenci√≥n usando vectores
            intent_category, confidence = self._classify_intent_vectorial(query)
            
            # Analizar contexto sem√°ntico
            semantic_context = self._analyze_semantic_context(query)
            
            # Generar respuestas sugeridas
            suggested_responses = self._generate_suggested_responses(query, intent_category, entities)
            
            return QueryAnalysis(
                original_query=query,
                processed_query=processed_query,
                intent_category=intent_category,
                confidence_score=confidence,
                extracted_entities=entities,
                semantic_context=semantic_context,
                suggested_responses=suggested_responses
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis sem√°ntico: {e}")
            return self._create_fallback_analysis(query)
    
    def _preprocess_query(self, query: str) -> str:
        """Preprocesa la consulta para an√°lisis"""
        # Convertir a min√∫sculas
        processed = query.lower()
        
        # Normalizar espacios
        processed = re.sub(r'\s+', ' ', processed).strip()
        
        # Expandir contracciones comunes
        contractions = {
            'q': 'que',
            'xq': 'porque',
            'pq': 'porque',
            'tb': 'tambi√©n',
            'tmb': 'tambi√©n',
        }
        
        for contraction, expansion in contractions.items():
            processed = re.sub(rf'\b{contraction}\b', expansion, processed)
        
        return processed
    
    def _extract_entities(self, query: str) -> Dict[str, Any]:
        """Extrae entidades espec√≠ficas de la consulta"""
        entities = {
            'tallas': [],
            'colores': [],
            'precios': [],
            'productos': [],
            'marcas': []
        }
        
        query_lower = query.lower()
        
        # Extraer tallas
        for pattern in self.entity_extractors['talla_patterns']:
            matches = re.findall(pattern, query_lower, re.IGNORECASE)
            entities['tallas'].extend(matches)
        
        # Extraer colores
        for pattern in self.entity_extractors['color_patterns']:
            matches = re.findall(pattern, query_lower)
            entities['colores'].extend(matches)
        
        # Extraer indicadores de precio
        for pattern in self.entity_extractors['precio_indicators']:
            if re.search(pattern, query_lower):
                entities['precios'].append('precio_mencionado')
        
        # Limpiar duplicados
        for key in entities:
            if isinstance(entities[key], list):
                entities[key] = list(set(entities[key]))
        
        return entities
    
    def _classify_intent_vectorial(self, query: str) -> Tuple[str, float]:
        """Clasifica la intenci√≥n usando an√°lisis vectorial"""
        if self.query_examples_vectors is None or self.training_data is None:
            return self._classify_intent_basic(query)
        
        try:
            # Vectorizar la consulta
            if self.sentence_model:
                query_vector = self.sentence_model.encode([query])
                similarities = cosine_similarity(query_vector, self.query_examples_vectors)[0]
            else:
                query_vector = self.fallback_vectorizer.transform([query])
                similarities = cosine_similarity(query_vector, self.query_examples_vectors)[0]
            
            # Encontrar la mejor coincidencia
            best_match_idx = np.argmax(similarities)
            confidence = similarities[best_match_idx]
            
            if confidence > 0.3:  # Umbral de confianza
                intent = self.training_data.iloc[best_match_idx]['categoria']
                self.performance_metrics['high_confidence_responses'] += 1
                return intent, confidence
            else:
                return self._classify_intent_basic(query)
                
        except Exception as e:
            logger.error(f"‚ùå Error en clasificaci√≥n vectorial: {e}")
            return self._classify_intent_basic(query)
    
    def _classify_intent_basic(self, query: str) -> Tuple[str, float]:
        """Clasificaci√≥n b√°sica de intenci√≥n como fallback"""
        query_lower = query.lower()
        
        # Reglas de clasificaci√≥n b√°sica con mayor precisi√≥n
        classification_rules = {
            'precio': {
                'keywords': ['precio', 'cuesta', 'vale', 'caro', 'barato', 'oferta', 'descuento', 'cu√°nto', 'valor', 'costo'],
                'confidence': 0.8
            },
            'talla': {
                'keywords': ['talla', 'medida', 'tama√±o', 'size', 'n√∫mero', 'ajuste', 'queda'],
                'confidence': 0.8
            },
            'disponibilidad': {
                'keywords': ['stock', 'disponible', 'hay', 'tienen', 'existencia', 'agotado', 'queda'],
                'confidence': 0.8
            },
            'color': {
                'keywords': ['color', 'viene', 'tonos', 'colores', 'negro', 'blanco', 'azul', 'rojo'],
                'confidence': 0.7
            },
            'envio': {
                'keywords': ['env√≠o', 'delivery', 'entrega', 'shipping', 'domicilio'],
                'confidence': 0.8
            },
            'pago': {
                'keywords': ['pago', 'tarjeta', 'efectivo', 'cuotas', 'transferencia'],
                'confidence': 0.8
            },
            'devolucion': {
                'keywords': ['devoluci√≥n', 'cambio', 'devolver', 'cambiar', 'garant√≠a'],
                'confidence': 0.8
            }
        }
        
        for intent, rule in classification_rules.items():
            if any(keyword in query_lower for keyword in rule['keywords']):
                return intent, rule['confidence']
        
        return 'general', 0.5
    
    def _analyze_semantic_context(self, query: str) -> Dict[str, float]:
        """Analiza el contexto sem√°ntico de la consulta"""
        context = {
            'urgencia': 0.0,
            'cortesia': 0.0,
            'especificidad': 0.0,
            'emocion_positiva': 0.0,
            'emocion_negativa': 0.0
        }
        
        query_lower = query.lower()
        
        # Detectar urgencia
        urgency_words = ['necesito', 'urgente', 'r√°pido', 'ahora', 'ya', 'inmediato']
        context['urgencia'] = sum(1 for word in urgency_words if word in query_lower) / len(urgency_words)
        
        # Detectar cortes√≠a
        courtesy_words = ['por favor', 'gracias', 'podr√≠an', 'me gustar√≠a', 'disculpe']
        context['cortesia'] = sum(1 for word in courtesy_words if word in query_lower) / len(courtesy_words)
        
        # Detectar especificidad (presencia de detalles)
        specific_indicators = len(re.findall(r'\b(talla|color|marca|modelo|n√∫mero)\s+\w+', query_lower))
        context['especificidad'] = min(specific_indicators / 3.0, 1.0)
        
        # Detectar emociones
        positive_words = ['genial', 'excelente', 'perfecto', 'me gusta', 'fant√°stico']
        negative_words = ['mal', 'terrible', 'horrible', 'no me gusta', 'decepcionado']
        
        context['emocion_positiva'] = sum(1 for word in positive_words if word in query_lower) / len(positive_words)
        context['emocion_negativa'] = sum(1 for word in negative_words if word in query_lower) / len(negative_words)
        
        return context
    
    def _generate_suggested_responses(self, query: str, intent: str, entities: Dict) -> List[str]:
        """Genera respuestas sugeridas basadas en el an√°lisis"""
        suggestions = []
        
        # Respuestas espec√≠ficas por intenci√≥n
        if intent == 'precio':
            if entities['productos']:
                suggestions.append(f"Te puedo ayudar con los precios de {', '.join(entities['productos'])}")
            else:
                suggestions.append("¬øQu√© producto espec√≠fico te interesa conocer el precio?")
        
        elif intent == 'talla':
            if entities['tallas']:
                suggestions.append(f"Verificar√© la disponibilidad de talla {', '.join(entities['tallas'])}")
            else:
                suggestions.append("¬øQu√© talla necesitas? Tengo la gu√≠a completa de medidas")
        
        elif intent == 'color':
            if entities['colores']:
                suggestions.append(f"Te muestro la disponibilidad en {', '.join(entities['colores'])}")
            else:
                suggestions.append("¬øQu√© colores te interesan? Tenemos una amplia gama")
        
        # Respuesta general siempre disponible
        suggestions.append("¬øEn qu√© m√°s puedo ayudarte?")
        
        return suggestions[:3]  # M√°ximo 3 sugerencias
    
    def find_best_products_advanced(self, query: str, limit: int = 5) -> List[ProductMatch]:
        """Encuentra productos usando b√∫squeda sem√°ntica avanzada"""
        if self.product_vectors is None:
            return []
        
        try:
            # Vectorizar la consulta
            if self.sentence_model:
                query_vector = self.sentence_model.encode([query])
                similarities = cosine_similarity(query_vector, self.product_vectors)[0]
            else:
                query_vector = self.fallback_vectorizer.transform([query])
                similarities = cosine_similarity(query_vector, self.product_vectors)[0]
            
            # Obtener √≠ndices ordenados por similitud
            top_indices = similarities.argsort()[-limit:][::-1]
            
            product_matches = []
            for idx in top_indices:
                if similarities[idx] > 0.1:  # Umbral m√≠nimo
                    producto = self.productos_data[idx].copy()
                    
                    # Calcular razones de coincidencia
                    match_reasons = self._calculate_match_reasons(query, producto, similarities[idx])
                    
                    # Determinar nivel de confianza
                    confidence_level = self._determine_confidence_level(similarities[idx])
                    
                    product_match = ProductMatch(
                        product=producto,
                        similarity_score=similarities[idx],
                        match_reasons=match_reasons,
                        confidence_level=confidence_level
                    )
                    
                    product_matches.append(product_match)
            
            if product_matches:
                self.performance_metrics['successful_matches'] += 1
            
            return product_matches
            
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda avanzada de productos: {e}")
            return []
    
    def _calculate_match_reasons(self, query: str, producto: Dict, similarity: float) -> List[str]:
        """Calcula las razones por las que un producto coincide con la consulta"""
        reasons = []
        query_lower = query.lower()
        
        # Coincidencias exactas
        if producto.get('nombre', '').lower() in query_lower:
            reasons.append("Coincidencia exacta en nombre")
        
        if producto.get('categoria', '').lower() in query_lower:
            reasons.append("Coincidencia en categor√≠a")
        
        # Coincidencias en colores
        for color in producto.get('colores', []):
            if color.lower() in query_lower:
                reasons.append(f"Disponible en {color}")
        
        # Coincidencias en tallas
        for talla in producto.get('tallas', []):
            if str(talla).lower() in query_lower:
                reasons.append(f"Disponible en talla {talla}")
        
        # Coincidencias sem√°nticas
        if similarity > 0.7:
            reasons.append("Alta similitud sem√°ntica")
        elif similarity > 0.5:
            reasons.append("Buena similitud sem√°ntica")
        
        # Productos destacados
        if producto.get('destacado'):
            reasons.append("Producto destacado")
        
        # Ofertas
        if producto.get('descuento', 0) > 0:
            reasons.append(f"En oferta ({producto['descuento']}% descuento)")
        
        return reasons[:3]  # M√°ximo 3 razones
    
    def _determine_confidence_level(self, similarity: float) -> str:
        """Determina el nivel de confianza basado en la similitud"""
        if similarity > 0.8:
            return "muy_alta"
        elif similarity > 0.6:
            return "alta"
        elif similarity > 0.4:
            return "media"
        elif similarity > 0.2:
            return "baja"
        else:
            return "muy_baja"
    
    def generate_intelligent_response(self, query: str) -> str:
        """Genera respuesta inteligente usando todo el sistema avanzado"""
        try:
            # An√°lisis completo de la consulta
            analysis = self.analyze_query_semantically(query)
            
            # B√∫squeda de productos relevantes
            product_matches = self.find_best_products_advanced(query, limit=3)
            
            # B√∫squeda en FAQ
            faq_response = self._search_faq_advanced(query)
            
            # Generar respuesta basada en el an√°lisis
            response = self._compose_intelligent_response(analysis, product_matches, faq_response)
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error generando respuesta inteligente: {e}")
            self.performance_metrics['fallback_responses'] += 1
            return self._get_fallback_response()
    
    def _search_faq_advanced(self, query: str) -> Optional[Dict]:
        """B√∫squeda avanzada en FAQ usando vectores"""
        if self.faq_vectors is None or not self.faq_data:
            return None
        
        try:
            if self.sentence_model:
                query_vector = self.sentence_model.encode([query])
                similarities = cosine_similarity(query_vector, self.faq_vectors)[0]
            else:
                query_vector = self.fallback_vectorizer.transform([query])
                similarities = cosine_similarity(query_vector, self.faq_vectors)[0]
            
            best_match_idx = np.argmax(similarities)
            
            if similarities[best_match_idx] > 0.4:  # Umbral para FAQ
                return self.faq_data[best_match_idx]
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda FAQ avanzada: {e}")
            return None
    
    def _compose_intelligent_response(self, analysis: QueryAnalysis, products: List[ProductMatch], faq: Optional[Dict]) -> str:
        """Compone respuesta inteligente basada en todos los an√°lisis"""
        response_parts = []
        
        # Saludo contextual
        if analysis.semantic_context.get('cortesia', 0) > 0.3:
            response_parts.append("¬°Por supuesto! Con gusto te ayudo.")
        else:
            response_parts.append("¬°Hola! Te ayudo con tu consulta.")
        
        # Respuesta espec√≠fica por intenci√≥n
        if analysis.intent_category == 'precio':
            response_parts.extend(self._generate_price_response_advanced(analysis, products))
        elif analysis.intent_category == 'talla':
            response_parts.extend(self._generate_size_response_advanced(analysis, products))
        elif analysis.intent_category == 'disponibilidad':
            response_parts.extend(self._generate_availability_response_advanced(analysis, products))
        elif analysis.intent_category == 'color':
            response_parts.extend(self._generate_color_response_advanced(analysis, products))
        elif faq:
            response_parts.append(f"\nüí° **{faq['pregunta']}**")
            response_parts.append(f"{faq['respuesta']}")
        else:
            response_parts.extend(self._generate_general_response_advanced(analysis, products))
        
        # Productos recomendados si hay coincidencias
        if products and analysis.intent_category != 'general':
            response_parts.append("\nüõçÔ∏è **Productos que podr√≠an interesarte:**")
            for i, match in enumerate(products[:2], 1):
                product = match.product
                response_parts.append(f"\n{i}. **{product['nombre']}**")
                response_parts.append(f"   üí∞ ${product.get('precio_final', product.get('precio', 'N/A'))}")
                if match.match_reasons:
                    response_parts.append(f"   ‚ú® {match.match_reasons[0]}")
        
        # Sugerencias adicionales
        if analysis.suggested_responses:
            response_parts.append(f"\nüí¨ {analysis.suggested_responses[0]}")
        
        return "\n".join(response_parts)
    
    def _generate_price_response_advanced(self, analysis: QueryAnalysis, products: List[ProductMatch]) -> List[str]:
        """Genera respuesta avanzada sobre precios"""
        parts = []
        
        if not products:
            parts.append("\nüí∞ Para darte informaci√≥n precisa de precios, ¬øpodr√≠as especificar qu√© producto te interesa?")
            parts.append("Tenemos precios desde $25.90 y constantes ofertas especiales.")
        else:
            parts.append("\nüí∞ **Informaci√≥n de Precios:**")
            for product in products[:2]:
                precio = product.product.get('precio_final', product.product.get('precio', 'N/A'))
                descuento = product.product.get('descuento', 0)
                
                if descuento > 0:
                    precio_original = product.product.get('precio_original', precio)
                    parts.append(f"‚Ä¢ **{product.product['nombre']}**: ${precio} (antes ${precio_original} - {descuento}% OFF)")
                else:
                    parts.append(f"‚Ä¢ **{product.product['nombre']}**: ${precio}")
        
        return parts
    
    def _generate_size_response_advanced(self, analysis: QueryAnalysis, products: List[ProductMatch]) -> List[str]:
        """Genera respuesta avanzada sobre tallas"""
        parts = []
        
        tallas_consultadas = analysis.extracted_entities.get('tallas', [])
        
        if not products:
            parts.append("\nüìè **Gu√≠a de Tallas:**")
            parts.append("‚Ä¢ **Ropa**: XS, S, M, L, XL, XXL")
            parts.append("‚Ä¢ **Pantalones**: 28-42")
            parts.append("‚Ä¢ **Calzado**: 35-45")
            if tallas_consultadas:
                parts.append(f"\n¬øTe interesa la talla {', '.join(tallas_consultadas)} en alg√∫n producto espec√≠fico?")
        else:
            parts.append("\nüìè **Informaci√≥n de Tallas:**")
            for product in products[:2]:
                tallas = product.product.get('tallas', [])
                parts.append(f"‚Ä¢ **{product.product['nombre']}**: {', '.join(map(str, tallas))}")
                
                if tallas_consultadas:
                    disponibles = [t for t in tallas_consultadas if str(t).upper() in [str(talla).upper() for talla in tallas]]
                    if disponibles:
                        parts.append(f"  ‚úÖ Talla {', '.join(disponibles)} disponible")
                    else:
                        parts.append(f"  ‚ùå Talla {', '.join(tallas_consultadas)} no disponible")
        
        return parts
    
    def _generate_availability_response_advanced(self, analysis: QueryAnalysis, products: List[ProductMatch]) -> List[str]:
        """Genera respuesta avanzada sobre disponibilidad"""
        parts = []
        
        if not products:
            parts.append("\nüì¶ Para verificar disponibilidad espec√≠fica, necesito saber qu√© producto te interesa.")
            parts.append("Puedo revisar nuestro inventario en tiempo real.")
        else:
            parts.append("\nüì¶ **Estado de Inventario:**")
            for product in products[:2]:
                stock = product.product.get('stock_total', 0)
                disponible = product.product.get('disponible', stock > 0)
                
                if disponible:
                    parts.append(f"‚Ä¢ **{product.product['nombre']}**: ‚úÖ Disponible ({stock} unidades)")
                else:
                    parts.append(f"‚Ä¢ **{product.product['nombre']}**: ‚ùå Agotado temporalmente")
                    parts.append("  üìÖ Pr√≥xima llegada: 3-5 d√≠as h√°biles")
        
        return parts
    
    def _generate_color_response_advanced(self, analysis: QueryAnalysis, products: List[ProductMatch]) -> List[str]:
        """Genera respuesta avanzada sobre colores"""
        parts = []
        
        colores_consultados = analysis.extracted_entities.get('colores', [])
        
        if not products:
            parts.append("\nüé® **Gama de Colores Disponibles:**")
            parts.append("Negro, Blanco, Azul, Rojo, Verde, Rosa, Gris, Marr√≥n, y m√°s")
            if colores_consultados:
                parts.append(f"\n¬øBuscas algo espec√≠fico en {', '.join(colores_consultados)}?")
        else:
            parts.append("\nüé® **Colores Disponibles:**")
            for product in products[:2]:
                colores = product.product.get('colores', [])
                parts.append(f"‚Ä¢ **{product.product['nombre']}**: {', '.join(colores)}")
                
                if colores_consultados:
                    coincidencias = [c for c in colores_consultados if any(c.lower() in color.lower() for color in colores)]
                    if coincidencias:
                        parts.append(f"  ‚úÖ Disponible en {', '.join(coincidencias)}")
        
        return parts
    
    def _generate_general_response_advanced(self, analysis: QueryAnalysis, products: List[ProductMatch]) -> List[str]:
        """Genera respuesta general avanzada"""
        parts = []
        
        urgencia = analysis.semantic_context.get('urgencia', 0)
        
        if urgencia > 0.5:
            parts.append("\n‚ö° Entiendo que necesitas informaci√≥n r√°pida.")
        
        parts.append("\nüõçÔ∏è **Estoy aqu√≠ para ayudarte con:**")
        parts.append("‚Ä¢ üí∞ Consultar precios y ofertas")
        parts.append("‚Ä¢ üìè Verificar tallas y disponibilidad")
        parts.append("‚Ä¢ üé® Mostrar colores disponibles")
        parts.append("‚Ä¢ üì¶ Informaci√≥n de env√≠os y pol√≠ticas")
        
        if products:
            parts.append("\n‚ú® Encontr√© algunos productos que podr√≠an interesarte:")
        
        return parts
    
    def _create_fallback_analysis(self, query: str) -> QueryAnalysis:
        """Crea an√°lisis b√°sico en caso de error"""
        return QueryAnalysis(
            original_query=query,
            processed_query=query.lower(),
            intent_category='general',
            confidence_score=0.3,
            extracted_entities={},
            semantic_context={},
            suggested_responses=["¬øEn qu√© puedo ayudarte espec√≠ficamente?"]
        )
    
    def _get_fallback_response(self) -> str:
        """Respuesta de emergencia"""
        return """üòä Disculpa, tuve un peque√±o problema procesando tu consulta.

üîç **Puedes preguntarme sobre:**
‚Ä¢ Precios y ofertas
‚Ä¢ Tallas disponibles  
‚Ä¢ Colores y estilos
‚Ä¢ Disponibilidad de productos

¬°Int√©ntalo de nuevo o s√© m√°s espec√≠fico!"""
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Obtiene m√©tricas de rendimiento del sistema"""
        if self.performance_metrics['total_queries'] > 0:
            success_rate = self.performance_metrics['successful_matches'] / self.performance_metrics['total_queries']
            confidence_rate = self.performance_metrics['high_confidence_responses'] / self.performance_metrics['total_queries']
        else:
            success_rate = 0
            confidence_rate = 0
        
        return {
            **self.performance_metrics,
            'success_rate': success_rate,
            'confidence_rate': confidence_rate,
            'model_type': 'sentence-transformers' if self.sentence_model else 'tfidf',
            'vector_cache_size': len(self.vector_cache)
        }
    
    def save_model_state(self, filepath: str) -> bool:
        """Guarda el estado del modelo para carga r√°pida"""
        try:
            state = {
                'product_vectors': self.product_vectors,
                'faq_vectors': self.faq_vectors,
                'query_examples_vectors': self.query_examples_vectors,
                'performance_metrics': self.performance_metrics,
                'model_name': self.model_name
            }
            
            with open(filepath, 'wb') as f:
                pickle.dump(state, f)
            
            logger.info(f"‚úÖ Estado del modelo guardado en {filepath}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error guardando estado: {e}")
            return False
    
    def load_model_state(self, filepath: str) -> bool:
        """Carga estado previamente guardado"""
        try:
            with open(filepath, 'rb') as f:
                state = pickle.load(f)
            
            self.product_vectors = state.get('product_vectors')
            self.faq_vectors = state.get('faq_vectors')
            self.query_examples_vectors = state.get('query_examples_vectors')
            self.performance_metrics = state.get('performance_metrics', self.performance_metrics)
            
            logger.info(f"‚úÖ Estado del modelo cargado desde {filepath}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando estado: {e}")
            return False

def main():
    """Funci√≥n de prueba del sistema avanzado"""
    print("ü§ñ Sistema de Respuesta Inteligente Avanzado - Fashion Store")
    print("=" * 70)
    
    # Inicializar sistema
    system = AdvancedIntelligentResponseSystem()
    
    # Inicializar embeddings
    system.initialize_embeddings_model()
    
    # Cargar datos
    if not system.load_data():
        print("‚ùå Error cargando datos")
        return
    
    # Crear vectores
    if not system.create_advanced_vectors():
        print("‚ùå Error creando vectores")
        return
    
    # Preguntas de prueba m√°s complejas
    test_questions = [
        "Hola, me interesa saber cu√°nto vale una camiseta en color negro talla M",
        "¬øTienen stock de jeans azules?",
        "Busco algo econ√≥mico para regalo",
        "¬øQu√© colores manejan en blazers?",
        "Necesito urgentemente informaci√≥n sobre env√≠os",
        "¬øPuedo devolver si no me queda bien?",
        "¬øHay descuentos para estudiantes?",
        "Me gustar√≠a ver zapatos c√≥modos para trabajo"
    ]
    
    print("\nüß™ PRUEBAS DEL SISTEMA AVANZADO")
    print("=" * 50)
    
    for question in test_questions:
        print(f"\n‚ùì Consulta: {question}")
        print("-" * 50)
        
        # An√°lisis sem√°ntico
        analysis = system.analyze_query_semantically(question)
        print(f"üß† Intenci√≥n: {analysis.intent_category} (confianza: {analysis.confidence_score:.2f})")
        print(f"üîç Entidades: {analysis.extracted_entities}")
        
        # Respuesta completa
        response = system.generate_intelligent_response(question)
        print(f"\nü§ñ Respuesta:\n{response}")
        print("\n" + "="*60)
    
    # Mostrar m√©tricas
    metrics = system.get_performance_metrics()
    print(f"\nüìä M√âTRICAS DE RENDIMIENTO:")
    print(f"Total consultas: {metrics['total_queries']}")
    print(f"Tasa de √©xito: {metrics['success_rate']:.2f}")
    print(f"Tasa de confianza alta: {metrics['confidence_rate']:.2f}")
    print(f"Tipo de modelo: {metrics['model_type']}")

if __name__ == "__main__":
    main()